{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tho121/udacity_aws/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import json\n",
    "import boto3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image has a coresponding metadata file that indicates the number of items in the image. These metadata files are accessed and parsed to identify only the images that contain 1-5 items. The filenames of these images are saved to the `full_list.json`, ordered by class. At this point, the file needs to be an json file with empty lists for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bucket='aft-vbi-pds'\n",
    "s3 = boto3.resource('s3')\n",
    "data_bucket = s3.Bucket(bucket)\n",
    "\n",
    "with open('full_list.json','r+') as file:\n",
    "    file_data = json.load(file)\n",
    "    \n",
    "    \n",
    "count = 0\n",
    "for object_summary in data_bucket.objects.filter(Prefix=\"metadata\"):\n",
    "    key = object_summary.key\n",
    "    if key.endswith(\".json\"):\n",
    "        data_location = 's3://{}/{}'.format(bucket, key)\n",
    "        \n",
    "        data = pd.read_json(data_location) \n",
    "\n",
    "        num = data['EXPECTED_QUANTITY']\n",
    "        \n",
    "        for n in num:\n",
    "            if n > 0 and n < 6:\n",
    "                file_data[str(n)].append(key)\n",
    "                count += 1\n",
    "                \n",
    "                if count % 10000 == 0:\n",
    "                    with open('check.json', 'w+') as file:\n",
    "                        json.dump(file_data, file)\n",
    "                    print(count)\n",
    "            break\n",
    "        \n",
    "with open('check.json','w+') as file:\n",
    "    json.dump(file_data, file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download images of the target classes, resize the images and upload to bucket. The `large_list.json` file contains the filenames of all the images that belong to the target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 1 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25987/25987 [38:54<00:00, 11.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 2 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48103/48103 [1:13:14<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 3 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56409/56409 [1:27:47<00:00, 10.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 4 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50384/50384 [1:17:35<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 5 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39117/39117 [1:01:22<00:00, 10.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def download_and_arrange_data():\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    with open('large_list.json', 'r') as f:\n",
    "        d=json.load(f)\n",
    "\n",
    "    for k, v in d.items():\n",
    "        print(f\"Downloading Images with {k} objects\")\n",
    "        directory=os.path.join('large_train_data', k)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        for file_path in tqdm(v):\n",
    "            file_name=os.path.basename(file_path).split('.')[0]+'.jpg'\n",
    "            s3_client.download_file('aft-vbi-pds', os.path.join('bin-images', file_name),\n",
    "                             os.path.join(directory, file_name))\n",
    "\n",
    "download_and_arrange_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1229\n",
      "2300\n",
      "2666\n",
      "2373\n",
      "1875\n"
     ]
    }
   ],
   "source": [
    "#TODO: Perform any data cleaning or data preprocessing\n",
    "print(len(os.listdir('large_train_data/1')))\n",
    "print(len(os.listdir('large_train_data/2')))\n",
    "print(len(os.listdir('large_train_data/3')))\n",
    "print(len(os.listdir('large_train_data/4')))\n",
    "print(len(os.listdir('large_train_data/5')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a random train-test split of 90-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(\"large_train_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(0.1 * len(dataset))\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, [len(dataset) - test_size, test_size])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the training and test splits locally and then upload to s3 bucket. This is so train and test data can be downloaded straight from the s3 bucket and be consistant across instances and training runs. Otherwise, the train-test split would be random each time the data is downloaded for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for img, label in train_data:\n",
    "    img.save(os.path.join(\"large_train\", str(label + 1), str(count) +\".jpg\"))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for img, label in test_data:\n",
    "    img.save(os.path.join(\"large_test\", str(label + 1), str(count) +\".jpg\"))\n",
    "    count += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize the images to avoid this preprocessing step when training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"resized_train\")\n",
    "os.mkdir(\"resized_train/1\")\n",
    "os.mkdir(\"resized_train/2\")\n",
    "os.mkdir(\"resized_train/3\")\n",
    "os.mkdir(\"resized_train/4\")\n",
    "os.mkdir(\"resized_train/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"resized_test\")\n",
    "os.mkdir(\"resized_test/1\")\n",
    "os.mkdir(\"resized_test/2\")\n",
    "os.mkdir(\"resized_test/3\")\n",
    "os.mkdir(\"resized_test/4\")\n",
    "os.mkdir(\"resized_test/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "transforms = T.Compose([T.Resize((224, 224))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(\"large_train\", transform=transforms)\n",
    "test_dataset = torchvision.datasets.ImageFolder(\"large_test\", transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for img, label in train_dataset:\n",
    "    img.save(os.path.join(\"resized_train\", str(label + 1), str(count) +\".jpg\"))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for img, label in test_dataset:\n",
    "    img.save(os.path.join(\"resized_test\", str(label + 1), str(count) +\".jpg\"))\n",
    "    count += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the images to a s3 bucket, including the originals just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path_to_data = sagemaker.Session().upload_data(bucket='bincapstone', \n",
    "                                                  path='resized_train', \n",
    "                                                  key_prefix='capstone/data/resized_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path_to_data = sagemaker.Session().upload_data(bucket='bincapstone', \n",
    "                                                  path='resized_test', \n",
    "                                                  key_prefix='capstone/data/resized_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path_to_data = sagemaker.Session().upload_data(bucket='bincapstone', \n",
    "                                                  path='large_train', \n",
    "                                                  key_prefix='capstone/data/large_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path_to_data_test = sagemaker.Session().upload_data(bucket='bincapstone', \n",
    "                                                  path='large_test', \n",
    "                                                  key_prefix='capstone/data/large_test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the normalization values for this dataset. Here the training and test data is assumed to be moved and renamed to local folders named `data/train_data` and `data/test_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(\"data/train_data\")\n",
    "test_dataset = torchvision.datasets.ImageFolder(\"data/test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=128, shuffle=False, num_workers=1)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_mean_std(loader):\n",
    "    cnt = 0\n",
    "    fst_moment = torch.empty(3)\n",
    "    snd_moment = torch.empty(3)\n",
    "    \n",
    "    for images, _ in loader:\n",
    "        b,c,h,w = images.shape\n",
    "        nb_pixels = b*h*w\n",
    "        sum_ = torch.sum(images, dim=[0,2,3])\n",
    "        sum_of_squares = torch.sum(images **2, dim=[0,2,3])\n",
    "        \n",
    "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
    "        snd_moment = (cnt * snd_moment + sum_of_squares) / (cnt + nb_pixels)\n",
    "        \n",
    "    mean = fst_moment\n",
    "    std = torch.sqrt(snd_moment - fst_moment ** 2)\n",
    "    return mean, std\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5300, 0.4495, 0.3624])\n",
      "tensor([0.1691, 0.1476, 0.1114])\n"
     ]
    }
   ],
   "source": [
    "mean,std = batch_mean_std(train_data_loader)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5206, 0.4400, 0.3570])\n",
      "tensor([0.1658, 0.1467, 0.1113])\n"
     ]
    }
   ],
   "source": [
    "mean,std = batch_mean_std(test_data_loader)\n",
    "print(mean)\n",
    "print(std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Sep 28 2021, 16:10:42) \n[GCC 9.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b9a16027b1face11683377a0f72853ed9096586e91733d0ba9340678d80f683"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
