{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "**TODO:** This is the part where you can train a model. The type or architecture of the model you use is not important. \n",
    "\n",
    "**Note:** You will need to use the `train.py` script to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name Tony to get Role path.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='SagemakerFullAccess')['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Declare your model training hyperparameter.\n",
    "hyperparameters = {\n",
    "    'batch_size': 128, \n",
    "    'lr': 0.001, \n",
    "    'epochs': 10, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpointing Path: s3://awscapstone/checkpoint-resnet-dc9edab3\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "bucket = \"awscapstone\"#sagemaker.Session().default_bucket()\n",
    "prefix = 'resnet'\n",
    "\n",
    "checkpoint_suffix = str(uuid.uuid4())[:8]\n",
    "checkpoint_s3_path = 's3://{}/checkpoint-{}-{}'.format(bucket,prefix,checkpoint_suffix)\n",
    "checkpoint_local_path='/opt/ml/checkpoints'\n",
    "\n",
    "print('Checkpointing Path: {}'.format(checkpoint_s3_path))\n",
    "\n",
    "use_spot_instances = True\n",
    "max_run = 144000    #4 hours per epoch, 10 epochs\n",
    "max_wait = 150000 if use_spot_instances else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your training estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point='train.py',\n",
    "    base_job_name='capstone',\n",
    "    role=role,\n",
    "    instance_count=4,\n",
    "    instance_type='ml.m5.2xlarge',\n",
    "    framework_version='1.12.0',\n",
    "    py_version='py38',\n",
    "    checkpoint_s3_uri=checkpoint_s3_path,\n",
    "    checkpoint_local_path=checkpoint_local_path,\n",
    "    hyperparameters=hyperparameters,\n",
    "    use_spot_instances=use_spot_instances,\n",
    "    max_run=max_run,\n",
    "    max_wait=max_wait\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-04 06:03:31 Starting - Starting the training job...\n",
      "2022-12-04 06:03:56 Starting - Preparing the instances for trainingProfilerReport-1670133811: InProgress\n",
      "......\n",
      "2022-12-04 06:04:56 Downloading - Downloading input data............\n",
      "2022-12-04 06:06:57 Training - Training image download completed. Training in progress.bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2022-12-04 06:06:59,877 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2022-12-04 06:06:59,879 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:06:59,888 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2022-12-04 06:06:59,896 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2022-12-04 06:06:59,939 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2022-12-04 06:06:59,941 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:06:59,948 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2022-12-04 06:06:59,955 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2022-12-04 06:07:00,348 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:07:00,357 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:07:00,368 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:07:00,376 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-3\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-3\",\n",
      "        \"algo-2\",\n",
      "        \"algo-4\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 128,\n",
      "        \"epochs\": 10,\n",
      "        \"lr\": 0.001\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-3\",\n",
      "                \"algo-2\",\n",
      "                \"algo-4\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"capstone-2022-12-04-06-03-29-795\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-149633813601/capstone-2022-12-04-06-03-29-795/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-3\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\",\n",
      "            \"algo-4\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-3\",\n",
      "                    \"algo-2\",\n",
      "                    \"algo-4\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch_size\":128,\"epochs\":10,\"lr\":0.001}\n",
      "SM_USER_ENTRY_POINT=train.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-3\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"test\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-3\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.m5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-149633813601/capstone-2022-12-04-06-03-29-795/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-3\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"current_instance_type\":\"ml.m5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":10,\"lr\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"job_name\":\"capstone-2022-12-04-06-03-29-795\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-149633813601/capstone-2022-12-04-06-03-29-795/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-3\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\n",
      "SM_USER_ARGS=[\"--batch_size\",\"128\",\"--epochs\",\"10\",\"--lr\",\"0.001\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_HP_BATCH_SIZE=128\n",
      "SM_HP_EPOCHS=10\n",
      "SM_HP_LR=0.001\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.8 train.py --batch_size 128 --epochs 10 --lr 0.001\n",
      "2022-12-04 06:07:00,361 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:07:00,372 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:07:00,385 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:07:00,392 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-3\",\n",
      "        \"algo-2\",\n",
      "        \"algo-4\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 128,\n",
      "        \"epochs\": 10,\n",
      "        \"lr\": 0.001\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-3\",\n",
      "                \"algo-2\",\n",
      "                \"algo-4\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"capstone-2022-12-04-06-03-29-795\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-149633813601/capstone-2022-12-04-06-03-29-795/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\",\n",
      "            \"algo-4\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-3\",\n",
      "                    \"algo-2\",\n",
      "                    \"algo-4\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch_size\":128,\"epochs\":10,\"lr\":0.001}\n",
      "SM_USER_ENTRY_POINT=train.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"test\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.m5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-149633813601/capstone-2022-12-04-06-03-29-795/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"current_instance_type\":\"ml.m5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":10,\"lr\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"capstone-2022-12-04-06-03-29-795\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-149633813601/capstone-2022-12-04-06-03-29-795/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\n",
      "SM_USER_ARGS=[\"--batch_size\",\"128\",\"--epochs\",\"10\",\"--lr\",\"0.001\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_HP_BATCH_SIZE=128\n",
      "SM_HP_EPOCHS=10\n",
      "SM_HP_LR=0.001\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.8 train.py --batch_size 128 --epochs 10 --lr 0.001\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2022-12-04 06:06:59,834 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2022-12-04 06:06:59,836 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:06:59,843 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2022-12-04 06:06:59,849 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2022-12-04 06:07:00,267 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:07:00,276 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:07:00,287 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:07:00,295 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-4\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-3\",\n",
      "        \"algo-2\",\n",
      "        \"algo-4\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 128,\n",
      "        \"epochs\": 10,\n",
      "        \"lr\": 0.001\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-3\",\n",
      "                \"algo-2\",\n",
      "                \"algo-4\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"capstone-2022-12-04-06-03-29-795\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-149633813601/capstone-2022-12-04-06-03-29-795/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-4\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\",\n",
      "            \"algo-4\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-3\",\n",
      "                    \"algo-2\",\n",
      "                    \"algo-4\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch_size\":128,\"epochs\":10,\"lr\":0.001}\n",
      "SM_USER_ENTRY_POINT=train.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-4\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"test\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-4\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.m5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-149633813601/capstone-2022-12-04-06-03-29-795/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-4\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"current_instance_type\":\"ml.m5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":10,\"lr\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"job_name\":\"capstone-2022-12-04-06-03-29-795\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-149633813601/capstone-2022-12-04-06-03-29-795/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-4\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\n",
      "SM_USER_ARGS=[\"--batch_size\",\"128\",\"--epochs\",\"10\",\"--lr\",\"0.001\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_HP_BATCH_SIZE=128\n",
      "SM_HP_EPOCHS=10\n",
      "SM_HP_LR=0.001\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.8 train.py --batch_size 128 --epochs 10 --lr 0.001\n",
      "Rank: 0\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2022-12-04 06:06:59,844 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2022-12-04 06:06:59,846 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:06:59,853 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2022-12-04 06:06:59,859 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2022-12-04 06:07:00,280 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:07:00,290 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:07:00,302 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2022-12-04 06:07:00,309 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-3\",\n",
      "        \"algo-2\",\n",
      "        \"algo-4\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\",\n",
      "        \"algo-3\",\n",
      "        \"algo-4\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 128,\n",
      "        \"epochs\": 10,\n",
      "        \"lr\": 0.001\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-3\",\n",
      "                \"algo-2\",\n",
      "                \"algo-4\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": false,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"capstone-2022-12-04-06-03-29-795\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-149633813601/capstone-2022-12-04-06-03-29-795/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\",\n",
      "            \"algo-3\",\n",
      "            \"algo-4\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-3\",\n",
      "                    \"algo-2\",\n",
      "                    \"algo-4\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"batch_size\":128,\"epochs\":10,\"lr\":0.001}\n",
      "SM_USER_ENTRY_POINT=train.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"test\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-2\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.m5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-149633813601/capstone-2022-12-04-06-03-29-795/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-2\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"current_instance_type\":\"ml.m5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"hyperparameters\":{\"batch_size\":128,\"epochs\":10,\"lr\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}},\"is_hetero\":false,\"is_master\":false,\"is_modelparallel_enabled\":null,\"job_name\":\"capstone-2022-12-04-06-03-29-795\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-149633813601/capstone-2022-12-04-06-03-29-795/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\",\"algo-3\",\"algo-4\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-3\",\"algo-2\",\"algo-4\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\n",
      "SM_USER_ARGS=[\"--batch_size\",\"128\",\"--epochs\",\"10\",\"--lr\",\"0.001\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_HP_BATCH_SIZE=128\n",
      "SM_HP_EPOCHS=10\n",
      "SM_HP_LR=0.001\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.8 train.py --batch_size 128 --epochs 10 --lr 0.001\n",
      "Rank: 1\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "0%|          | 0.00/83.3M [00:00<?, ?B/s]\n",
      "Rank: 3\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "0%|          | 0.00/83.3M [00:00<?, ?B/s]\n",
      "30%|███       | 25.0M/83.3M [00:00<00:00, 262MB/s]\n",
      "63%|██████▎   | 52.6M/83.3M [00:00<00:00, 278MB/s]\n",
      "98%|█████████▊| 81.6M/83.3M [00:00<00:00, 290MB/s]\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 285MB/s]\n",
      "Rank: 2\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "0%|          | 0.00/83.3M [00:00<?, ?B/s]\n",
      "43%|████▎     | 36.0M/83.3M [00:00<00:00, 377MB/s]\n",
      "86%|████████▋ | 71.9M/83.3M [00:00<00:00, 283MB/s]\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 272MB/s]\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "0%|          | 0.00/83.3M [00:00<?, ?B/s]\n",
      "15%|█▍        | 12.4M/83.3M [00:00<00:00, 130MB/s]\n",
      "30%|██▉       | 24.8M/83.3M [00:00<00:00, 118MB/s]\n",
      "43%|████▎     | 36.1M/83.3M [00:00<00:00, 75.0MB/s]\n",
      "25%|██▍       | 20.6M/83.3M [00:00<00:00, 216MB/s]\n",
      "53%|█████▎    | 43.8M/83.3M [00:00<00:00, 232MB/s]\n",
      "79%|███████▉  | 65.9M/83.3M [00:00<00:00, 229MB/s]\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 228MB/s]\n",
      "[2022-12-04 06:07:04.768 algo-4:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-12-04 06:07:04.763 algo-3:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "59%|█████▉    | 49.1M/83.3M [00:00<00:00, 75.7MB/s]\n",
      "78%|███████▊  | 64.9M/83.3M [00:00<00:00, 75.6MB/s]\n",
      "87%|████████▋ | 72.5M/83.3M [00:01<00:00, 68.3MB/s]\n",
      "100%|██████████| 83.3M/83.3M [00:01<00:00, 80.9MB/s]\n",
      "[2022-12-04 06:07:04.908 algo-2:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2022-12-04 06:07:05.453 algo-2:27 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2022-12-04 06:07:05.326 algo-4:27 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[2022-12-04 06:07:05.290 algo-3:27 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[2022-12-04 06:07:05.772 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "/opt/conda/lib/python3.8/site-packages/smdebug-1.0.19b20220829-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "[2022-12-04 06:07:06.348 algo-1:27 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "3200\n",
      "Loss 0.011632748879492283, Accuracy 32.21875%\n",
      "3200\n",
      "Loss 0.011837664060294628, Accuracy 30.343750000000004%\n",
      "3200\n",
      "Loss 0.011847656220197678, Accuracy 30.1875%\n",
      "3200\n",
      "Loss 0.01187868695706129, Accuracy 30.15625%\n",
      "6400\n",
      "Loss 0.011089847423136234, Accuracy 34.171875%\n",
      "6400\n",
      "Loss 0.011116490699350834, Accuracy 33.328125%\n",
      "6400\n",
      "Loss 0.011172161437571049, Accuracy 33.640625%\n",
      "6400\n",
      "Loss 0.011184610426425934, Accuracy 33.9375%\n",
      "9600\n",
      "Loss 0.010786809958517551, Accuracy 36.302083333333336%\n",
      "9600\n",
      "Loss 0.010740876197814941, Accuracy 36.16666666666667%\n",
      "9600\n",
      "Loss 0.010850444436073303, Accuracy 35.833333333333336%\n",
      "9600\n",
      "Loss 0.010795599780976772, Accuracy 35.270833333333336%\n",
      "12800\n",
      "Loss 0.010580918751657009, Accuracy 37.5078125%\n",
      "12800\n",
      "Loss 0.010524267330765724, Accuracy 37.3671875%\n",
      "12800\n",
      "Loss 0.01067125890403986, Accuracy 36.4375%\n",
      "12800\n",
      "Loss 0.010599986650049686, Accuracy 36.328125%\n",
      "16000\n",
      "Loss 0.0104184839874506, Accuracy 38.30625%\n",
      "16000\n",
      "Loss 0.010368261486291885, Accuracy 38.48125%\n",
      "16000\n",
      "Loss 0.010508611798286438, Accuracy 37.4125%\n",
      "16000\n",
      "Loss 0.010442101396620274, Accuracy 37.55%\n",
      "19200\n",
      "Loss 0.010265744291245937, Accuracy 38.9375%\n",
      "19200\n",
      "Loss 0.010396413505077362, Accuracy 38.140625%\n",
      "19200\n",
      "Loss 0.010328254662454128, Accuracy 38.427083333333336%\n",
      "19200\n",
      "Loss 0.010284017771482468, Accuracy 39.08333333333333%\n",
      "22400\n",
      "Loss 0.010294131003320217, Accuracy 38.77232142857142%\n",
      "22400\n",
      "Loss 0.010230245999991894, Accuracy 39.0625%\n",
      "22400\n",
      "Loss 0.01016676053404808, Accuracy 39.901785714285715%\n",
      "22400\n",
      "Loss 0.010175311006605625, Accuracy 39.401785714285715%\n",
      "25600\n",
      "Loss 0.010084726847708225, Accuracy 40.44921875%\n",
      "25600\n",
      "Loss 0.010120159015059471, Accuracy 39.9296875%\n",
      "25600\n",
      "Loss 0.010218334384262562, Accuracy 39.44921875%\n",
      "25600\n",
      "Loss 0.010173073038458824, Accuracy 39.41796875%\n",
      "28800\n",
      "Loss 0.010050599463284016, Accuracy 40.43055555555555%\n",
      "28800\n",
      "Loss 0.010117504745721817, Accuracy 40.12847222222222%\n",
      "28800\n",
      "Loss 0.010095137171447277, Accuracy 39.93055555555556%\n",
      "28800\n",
      "Loss 0.01000683568418026, Accuracy 40.85416666666667%\n",
      "32000\n",
      "Loss 0.009953062050044537, Accuracy 41.168749999999996%\n",
      "32000\n",
      "Loss 0.00999259389936924, Accuracy 40.728125%\n",
      "32000\n",
      "Loss 0.010053598321974277, Accuracy 40.525%\n",
      "32000\n",
      "Loss 0.010039301589131355, Accuracy 40.228125%\n",
      "35200\n",
      "Loss 0.010004664771258831, Accuracy 40.88068181818182%\n",
      "35200\n",
      "Loss 0.009990542195737362, Accuracy 40.49147727272727%\n",
      "35200\n",
      "Loss 0.009906552731990814, Accuracy 41.49431818181818%\n",
      "35200\n",
      "Loss 0.00994841381907463, Accuracy 41.10795454545455%\n",
      "38400\n",
      "Loss 0.009900025092065334, Accuracy 41.510416666666664%\n",
      "38400\n",
      "Loss 0.009943410754203796, Accuracy 41.15625%\n",
      "38400\n",
      "Loss 0.00994291715323925, Accuracy 40.872395833333336%\n",
      "38400\n",
      "Loss 0.009857564233243465, Accuracy 41.791666666666664%\n",
      "41600\n",
      "Loss 0.009815114550292492, Accuracy 42.02884615384615%\n",
      "41600\n",
      "Loss 0.009869982488453388, Accuracy 41.64182692307693%\n",
      "41600\n",
      "Loss 0.00989760085940361, Accuracy 41.49759615384615%\n",
      "41600\n",
      "Loss 0.009911494329571724, Accuracy 41.12980769230769%\n",
      "44800\n",
      "Loss 0.009771028533577919, Accuracy 42.341517857142854%\n",
      "44800\n",
      "Loss 0.009819813072681427, Accuracy 41.96651785714286%\n",
      "44800\n",
      "Loss 0.009833255782723427, Accuracy 41.988839285714285%\n",
      "44800\n",
      "Loss 0.009854461997747421, Accuracy 41.49330357142857%\n",
      "48000\n",
      "Loss 0.009771039709448814, Accuracy 42.28125%\n",
      "48000\n",
      "Loss 0.009780754335224628, Accuracy 42.3625%\n",
      "48000\n",
      "Loss 0.009813331998884678, Accuracy 41.862500000000004%\n",
      "48000\n",
      "Loss 0.00973852351307869, Accuracy 42.55%\n",
      "49500\n",
      "Loss 0.009738495573401451, Accuracy 42.614141414141415%\n",
      "Loss 0.009738495573401451, Accuracy 42.614141414141415%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.009762519970536232, Accuracy 42.36767676767676%\n",
      "Loss 0.009762519970536232, Accuracy 42.36767676767676%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.00977031048387289, Accuracy 42.51919191919192%\n",
      "Loss 0.00977031048387289, Accuracy 42.51919191919192%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.009797479026019573, Accuracy 42.01010101010101%\n",
      "Loss 0.009797479026019573, Accuracy 42.01010101010101%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 46%\n",
      "3200\n",
      "Test set: running accuracy: 45%\n",
      "3200\n",
      "Test set: running accuracy: 44%\n",
      "3200\n",
      "Test set: running accuracy: 44%\n",
      "6400\n",
      "Test set: running accuracy: 45%\n",
      "6400\n",
      "Test set: running accuracy: 44%\n",
      "6400\n",
      "Test set: running accuracy: 43%\n",
      "6400\n",
      "Test set: running accuracy: 44%\n",
      "9600\n",
      "Test set: running accuracy: 45%\n",
      "9600\n",
      "Test set: running accuracy: 44%\n",
      "9600\n",
      "Test set: running accuracy: 43%\n",
      "9600\n",
      "Test set: running accuracy: 44%\n",
      "12800\n",
      "Test set: running accuracy: 45%\n",
      "12800\n",
      "Test set: running accuracy: 43%\n",
      "12800\n",
      "Test set: running accuracy: 44%\n",
      "12800\n",
      "Test set: running accuracy: 44%\n",
      "16000\n",
      "Test set: running accuracy: 45%\n",
      "16000\n",
      "Test set: running accuracy: 43%\n",
      "16000\n",
      "Test set: running accuracy: 44%\n",
      "16000\n",
      "Test set: running accuracy: 44%\n",
      "19200\n",
      "Test set: running accuracy: 45%\n",
      "19200\n",
      "Test set: running accuracy: 43%\n",
      "19200\n",
      "Test set: running accuracy: 45%\n",
      "22000\n",
      "Test set: running accuracy: 45%\n",
      "Test set: Accuracy: 45%\n",
      "19200\n",
      "Test set: running accuracy: 45%\n",
      "22000\n",
      "Test set: running accuracy: 43%\n",
      "Test set: Accuracy: 43%\n",
      "22000\n",
      "Test set: running accuracy: 45%\n",
      "Test set: Accuracy: 45%\n",
      "22000\n",
      "Test set: running accuracy: 45%\n",
      "Test set: Accuracy: 45%\n",
      "3200\n",
      "Loss 0.009143308736383915, Accuracy 46.9375%\n",
      "3200\n",
      "Loss 0.009224248118698597, Accuracy 46.4375%\n",
      "3200\n",
      "Loss 0.00925351306796074, Accuracy 44.9375%\n",
      "3200\n",
      "Loss 0.009111529216170311, Accuracy 46.96875%\n",
      "6400\n",
      "Loss 0.00911152083426714, Accuracy 47.25%\n",
      "6400\n",
      "Loss 0.009204615838825703, Accuracy 45.71875%\n",
      "6400\n",
      "Loss 0.0091069545596838, Accuracy 46.765625%\n",
      "6400\n",
      "Loss 0.00917018111795187, Accuracy 46.40625%\n",
      "9600\n",
      "Loss 0.009037611074745655, Accuracy 47.84375%\n",
      "9600\n",
      "Loss 0.009116760455071926, Accuracy 46.59375%\n",
      "9600\n",
      "Loss 0.0090951444581151, Accuracy 47.072916666666664%\n",
      "9600\n",
      "Loss 0.009127825498580933, Accuracy 46.65625%\n",
      "12800\n",
      "Loss 0.00902160257101059, Accuracy 47.625%\n",
      "12800\n",
      "Loss 0.009135055355727673, Accuracy 46.4140625%\n",
      "12800\n",
      "Loss 0.009098419919610023, Accuracy 46.6953125%\n",
      "12800\n",
      "Loss 0.009069113060832024, Accuracy 47.328125%\n",
      "16000\n",
      "Loss 0.009082158096134663, Accuracy 46.7125%\n",
      "16000\n",
      "Loss 0.009071535430848598, Accuracy 46.9375%\n",
      "16000\n",
      "Loss 0.009019631892442703, Accuracy 47.5625%\n",
      "16000\n",
      "Loss 0.008966434746980667, Accuracy 48.131249999999994%\n",
      "19200\n",
      "Loss 0.008970697410404682, Accuracy 47.802083333333336%\n",
      "19200\n",
      "Loss 0.008963092230260372, Accuracy 48.03125%\n",
      "19200\n",
      "Loss 0.009072932414710522, Accuracy 46.979166666666664%\n",
      "19200\n",
      "Loss 0.009040364064276218, Accuracy 47.151041666666664%\n",
      "22400\n",
      "Loss 0.008937694132328033, Accuracy 48.17857142857142%\n",
      "22400\n",
      "Loss 0.009045089595019817, Accuracy 47.27232142857143%\n",
      "22400\n",
      "Loss 0.00902136042714119, Accuracy 47.33482142857143%\n",
      "22400\n",
      "Loss 0.008927957154810429, Accuracy 48.089285714285715%\n",
      "25600\n",
      "Loss 0.008938245475292206, Accuracy 48.2578125%\n",
      "25600\n",
      "Loss 0.009024892002344131, Accuracy 47.4453125%\n",
      "25600\n",
      "Loss 0.009016602300107479, Accuracy 47.4140625%\n",
      "25600\n",
      "Loss 0.008915216661989689, Accuracy 48.234375%\n",
      "28800\n",
      "Loss 0.008885989896953106, Accuracy 48.395833333333336%\n",
      "28800\n",
      "Loss 0.008920731022953987, Accuracy 48.388888888888886%\n",
      "28800\n",
      "Loss 0.008975287899374962, Accuracy 47.857638888888886%\n",
      "28800\n",
      "Loss 0.008988694287836552, Accuracy 47.47569444444444%\n",
      "32000\n",
      "Loss 0.008893120102584362, Accuracy 48.40625%\n",
      "32000\n",
      "Loss 0.008911043405532837, Accuracy 48.465625%\n",
      "32000\n",
      "Loss 0.008958067744970322, Accuracy 47.940625%\n",
      "32000\n",
      "Loss 0.008988866582512856, Accuracy 47.44375%\n",
      "35200\n",
      "Loss 0.008958028629422188, Accuracy 47.95738636363636%\n",
      "35200\n",
      "Loss 0.008969425223767757, Accuracy 47.63068181818182%\n",
      "35200\n",
      "Loss 0.008888986892998219, Accuracy 48.43465909090909%\n",
      "35200\n",
      "Loss 0.00891751330345869, Accuracy 48.41193181818182%\n",
      "38400\n",
      "Loss 0.008931608870625496, Accuracy 48.083333333333336%\n",
      "38400\n",
      "Loss 0.008949565701186657, Accuracy 47.791666666666664%\n",
      "38400\n",
      "Loss 0.008870855905115604, Accuracy 48.520833333333336%\n",
      "38400\n",
      "Loss 0.008909661322832108, Accuracy 48.53125%\n",
      "41600\n",
      "Loss 0.008909779600799084, Accuracy 48.58413461538461%\n",
      "41600\n",
      "Loss 0.008916082791984081, Accuracy 48.20432692307692%\n",
      "41600\n",
      "Loss 0.008947453461587429, Accuracy 47.89663461538461%\n",
      "41600\n",
      "Loss 0.008863863535225391, Accuracy 48.56490384615385%\n",
      "44800\n",
      "Loss 0.008889813907444477, Accuracy 48.70535714285714%\n",
      "44800\n",
      "Loss 0.00888768956065178, Accuracy 48.35267857142857%\n",
      "44800\n",
      "Loss 0.00892549566924572, Accuracy 48.075892857142854%\n",
      "44800\n",
      "Loss 0.008849804289638996, Accuracy 48.70982142857142%\n",
      "48000\n",
      "Loss 0.008838774636387825, Accuracy 48.75833333333333%\n",
      "48000\n",
      "Loss 0.008862169459462166, Accuracy 48.827083333333334%\n",
      "48000\n",
      "Loss 0.008862444199621677, Accuracy 48.50625%\n",
      "48000\n",
      "Loss 0.008907769806683064, Accuracy 48.18333333333334%\n",
      "49500\n",
      "Loss 0.008863715454936028, Accuracy 48.55959595959596%\n",
      "Loss 0.008863715454936028, Accuracy 48.55959595959596%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.008900493383407593, Accuracy 48.339393939393936%\n",
      "Loss 0.008900493383407593, Accuracy 48.339393939393936%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.008844737894833088, Accuracy 48.773737373737376%\n",
      "Loss 0.008844737894833088, Accuracy 48.773737373737376%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.008861961774528027, Accuracy 48.826262626262626%\n",
      "Loss 0.008861961774528027, Accuracy 48.826262626262626%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 48%\n",
      "3200\n",
      "Test set: running accuracy: 50%\n",
      "3200\n",
      "Test set: running accuracy: 48%\n",
      "3200\n",
      "Test set: running accuracy: 49%\n",
      "6400\n",
      "Test set: running accuracy: 48%\n",
      "6400\n",
      "Test set: running accuracy: 49%\n",
      "6400\n",
      "Test set: running accuracy: 48%\n",
      "6400\n",
      "Test set: running accuracy: 49%\n",
      "9600\n",
      "Test set: running accuracy: 48%\n",
      "9600\n",
      "Test set: running accuracy: 49%\n",
      "9600\n",
      "Test set: running accuracy: 48%\n",
      "9600\n",
      "Test set: running accuracy: 49%\n",
      "12800\n",
      "Test set: running accuracy: 48%\n",
      "12800\n",
      "Test set: running accuracy: 49%\n",
      "12800\n",
      "Test set: running accuracy: 49%\n",
      "12800\n",
      "Test set: running accuracy: 48%\n",
      "16000\n",
      "Test set: running accuracy: 49%\n",
      "16000\n",
      "Test set: running accuracy: 49%\n",
      "16000\n",
      "Test set: running accuracy: 48%\n",
      "16000\n",
      "Test set: running accuracy: 49%\n",
      "19200\n",
      "Test set: running accuracy: 49%\n",
      "19200\n",
      "Test set: running accuracy: 49%\n",
      "22000\n",
      "Test set: running accuracy: 49%\n",
      "Test set: Accuracy: 49%\n",
      "19200\n",
      "Test set: running accuracy: 49%\n",
      "19200\n",
      "Test set: running accuracy: 48%\n",
      "22000\n",
      "Test set: running accuracy: 49%\n",
      "Test set: Accuracy: 49%\n",
      "22000\n",
      "Test set: running accuracy: 49%\n",
      "Test set: Accuracy: 49%\n",
      "22000\n",
      "Test set: running accuracy: 48%\n",
      "Test set: Accuracy: 48%\n",
      "3200\n",
      "Loss 0.00865261908620596, Accuracy 50.31250000000001%\n",
      "3200\n",
      "Loss 0.008660426363348961, Accuracy 50.5625%\n",
      "3200\n",
      "Loss 0.008712809532880783, Accuracy 48.8125%\n",
      "3200\n",
      "Loss 0.008677974343299866, Accuracy 49.4375%\n",
      "6400\n",
      "Loss 0.00860575120896101, Accuracy 50.625%\n",
      "6400\n",
      "Loss 0.008660299703478813, Accuracy 50.375%\n",
      "6400\n",
      "Loss 0.008712942712008953, Accuracy 49.765625%\n",
      "6400\n",
      "Loss 0.008592533878982067, Accuracy 50.390625%\n",
      "9600\n",
      "Loss 0.008596613071858883, Accuracy 50.90625%\n",
      "9600\n",
      "Loss 0.008653518743813038, Accuracy 50.48958333333333%\n",
      "9600\n",
      "Loss 0.008598171174526215, Accuracy 50.5625%\n",
      "9600\n",
      "Loss 0.008543876931071281, Accuracy 51.07291666666667%\n",
      "12800\n",
      "Loss 0.00857163779437542, Accuracy 51.0625%\n",
      "12800\n",
      "Loss 0.008691774681210518, Accuracy 50.1953125%\n",
      "12800\n",
      "Loss 0.008606575429439545, Accuracy 50.1484375%\n",
      "12800\n",
      "Loss 0.008553048595786095, Accuracy 50.78125%\n",
      "16000\n",
      "Loss 0.008637897670269012, Accuracy 50.31875%\n",
      "16000\n",
      "Loss 0.008578854613006115, Accuracy 50.6%\n",
      "16000\n",
      "Loss 0.008543234318494797, Accuracy 50.6375%\n",
      "16000\n",
      "Loss 0.008524741046130657, Accuracy 51.40625%\n",
      "19200\n",
      "Loss 0.008504863828420639, Accuracy 50.989583333333336%\n",
      "19200\n",
      "Loss 0.008523995988070965, Accuracy 51.197916666666664%\n",
      "19200\n",
      "Loss 0.008648758754134178, Accuracy 50.296875%\n",
      "19200\n",
      "Loss 0.008556612767279148, Accuracy 50.96874999999999%\n",
      "22400\n",
      "Loss 0.008492108434438705, Accuracy 51.45089285714286%\n",
      "22400\n",
      "Loss 0.00862190779298544, Accuracy 50.50892857142857%\n",
      "22400\n",
      "Loss 0.008553894236683846, Accuracy 50.89732142857143%\n",
      "22400\n",
      "Loss 0.008478917181491852, Accuracy 51.10267857142857%\n",
      "25600\n",
      "Loss 0.008598150685429573, Accuracy 50.66406249999999%\n",
      "25600\n",
      "Loss 0.008467094972729683, Accuracy 51.21875%\n",
      "25600\n",
      "Loss 0.008496489375829697, Accuracy 51.58203125000001%\n",
      "25600\n",
      "Loss 0.008557331748306751, Accuracy 50.796875%\n",
      "28800\n",
      "Loss 0.008477913215756416, Accuracy 51.604166666666664%\n",
      "28800\n",
      "Loss 0.008555677719414234, Accuracy 51.05208333333333%\n",
      "28800\n",
      "Loss 0.00853965524584055, Accuracy 50.82986111111111%\n",
      "28800\n",
      "Loss 0.008439863100647926, Accuracy 51.326388888888886%\n",
      "32000\n",
      "Loss 0.00845528207719326, Accuracy 51.20312500000001%\n",
      "32000\n",
      "Loss 0.008474883623421192, Accuracy 51.65%\n",
      "32000\n",
      "Loss 0.008559128269553185, Accuracy 50.93124999999999%\n",
      "32000\n",
      "Loss 0.008549985475838184, Accuracy 50.759375%\n",
      "35200\n",
      "Loss 0.008478263393044472, Accuracy 51.67329545454545%\n",
      "35200\n",
      "Loss 0.008542254567146301, Accuracy 51.03124999999999%\n",
      "35200\n",
      "Loss 0.008528979495167732, Accuracy 50.88352272727272%\n",
      "35200\n",
      "Loss 0.008454510010778904, Accuracy 51.272727272727266%\n",
      "38400\n",
      "Loss 0.008519614115357399, Accuracy 51.14062499999999%\n",
      "38400\n",
      "Loss 0.008518839254975319, Accuracy 50.90625%\n",
      "38400\n",
      "Loss 0.008447233587503433, Accuracy 51.41927083333333%\n",
      "38400\n",
      "Loss 0.00847457442432642, Accuracy 51.692708333333336%\n",
      "41600\n",
      "Loss 0.008508597500622272, Accuracy 51.16586538461539%\n",
      "41600\n",
      "Loss 0.008520051836967468, Accuracy 50.88461538461539%\n",
      "41600\n",
      "Loss 0.008441426791250706, Accuracy 51.46634615384615%\n",
      "41600\n",
      "Loss 0.008479074575006962, Accuracy 51.55288461538462%\n",
      "44800\n",
      "Loss 0.008429940789937973, Accuracy 51.61160714285714%\n",
      "44800\n",
      "Loss 0.008460217155516148, Accuracy 51.64732142857142%\n",
      "44800\n",
      "Loss 0.008478427305817604, Accuracy 51.34821428571429%\n",
      "44800\n",
      "Loss 0.008497115224599838, Accuracy 50.966517857142854%\n",
      "48000\n",
      "Loss 0.0084464680403471, Accuracy 51.71666666666667%\n",
      "48000\n",
      "Loss 0.008461184799671173, Accuracy 51.44375%\n",
      "48000\n",
      "Loss 0.008488531224429607, Accuracy 51.025%\n",
      "48000\n",
      "Loss 0.008421678096055984, Accuracy 51.672916666666666%\n",
      "49500\n",
      "Loss 0.00843116920441389, Accuracy 51.67070707070707%\n",
      "Loss 0.00843116920441389, Accuracy 51.67070707070707%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.008442436344921589, Accuracy 51.76767676767676%\n",
      "Loss 0.008442436344921589, Accuracy 51.76767676767676%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.008464353159070015, Accuracy 51.49292929292929%\n",
      "Loss 0.008464353159070015, Accuracy 51.49292929292929%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.008480614982545376, Accuracy 51.13131313131313%\n",
      "Loss 0.008480614982545376, Accuracy 51.13131313131313%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 50%\n",
      "3200\n",
      "Test set: running accuracy: 49%\n",
      "3200\n",
      "Test set: running accuracy: 49%\n",
      "3200\n",
      "Test set: running accuracy: 49%\n",
      "6400\n",
      "Test set: running accuracy: 50%\n",
      "6400\n",
      "Test set: running accuracy: 50%\n",
      "6400\n",
      "Test set: running accuracy: 50%\n",
      "6400\n",
      "Test set: running accuracy: 49%\n",
      "9600\n",
      "Test set: running accuracy: 50%\n",
      "9600\n",
      "Test set: running accuracy: 50%\n",
      "9600\n",
      "Test set: running accuracy: 50%\n",
      "9600\n",
      "Test set: running accuracy: 49%\n",
      "12800\n",
      "Test set: running accuracy: 50%\n",
      "12800\n",
      "Test set: running accuracy: 50%\n",
      "12800\n",
      "Test set: running accuracy: 50%\n",
      "12800\n",
      "Test set: running accuracy: 50%\n",
      "16000\n",
      "Test set: running accuracy: 50%\n",
      "16000\n",
      "Test set: running accuracy: 50%\n",
      "16000\n",
      "Test set: running accuracy: 50%\n",
      "16000\n",
      "Test set: running accuracy: 50%\n",
      "19200\n",
      "Test set: running accuracy: 49%\n",
      "19200\n",
      "Test set: running accuracy: 49%\n",
      "19200\n",
      "Test set: running accuracy: 50%\n",
      "19200\n",
      "Test set: running accuracy: 50%\n",
      "22000\n",
      "Test set: running accuracy: 49%\n",
      "Test set: Accuracy: 49%\n",
      "22000\n",
      "Test set: running accuracy: 49%\n",
      "Test set: Accuracy: 49%\n",
      "22000\n",
      "Test set: running accuracy: 50%\n",
      "Test set: Accuracy: 50%\n",
      "22000\n",
      "Test set: running accuracy: 50%\n",
      "Test set: Accuracy: 50%\n",
      "3200\n",
      "Loss 0.008309846743941307, Accuracy 52.96875%\n",
      "3200\n",
      "Loss 0.008333411999046803, Accuracy 50.96874999999999%\n",
      "3200\n",
      "Loss 0.008375543169677258, Accuracy 52.34375%\n",
      "3200\n",
      "Loss 0.00836997665464878, Accuracy 52.09375000000001%\n",
      "6400\n",
      "Loss 0.008356672711670399, Accuracy 52.15625000000001%\n",
      "6400\n",
      "Loss 0.00833875685930252, Accuracy 53.078125%\n",
      "6400\n",
      "Loss 0.008224018849432468, Accuracy 52.859375%\n",
      "6400\n",
      "Loss 0.00825529359281063, Accuracy 52.53124999999999%\n",
      "9600\n",
      "Loss 0.008214641362428665, Accuracy 52.947916666666664%\n",
      "9600\n",
      "Loss 0.008267727680504322, Accuracy 52.760416666666664%\n",
      "9600\n",
      "Loss 0.00831324141472578, Accuracy 53.11458333333333%\n",
      "9600\n",
      "Loss 0.008246287703514099, Accuracy 52.84375%\n",
      "12800\n",
      "Loss 0.008330874145030975, Accuracy 53.03125%\n",
      "12800\n",
      "Loss 0.008259951137006283, Accuracy 52.98437499999999%\n",
      "12800\n",
      "Loss 0.008234791457653046, Accuracy 52.85156250000001%\n",
      "12800\n",
      "Loss 0.008242025040090084, Accuracy 52.98437499999999%\n",
      "16000\n",
      "Loss 0.008190673775970936, Accuracy 53.5%\n",
      "16000\n",
      "Loss 0.008294899947941303, Accuracy 52.9875%\n",
      "16000\n",
      "Loss 0.008246984332799911, Accuracy 53.193749999999994%\n",
      "16000\n",
      "Loss 0.00820665992796421, Accuracy 53.14375%\n",
      "19200\n",
      "Loss 0.008289876393973827, Accuracy 52.83333333333333%\n",
      "19200\n",
      "Loss 0.008218523114919662, Accuracy 53.53125%\n",
      "19200\n",
      "Loss 0.008185179904103279, Accuracy 53.234375%\n",
      "19200\n",
      "Loss 0.008191143162548542, Accuracy 53.40625%\n",
      "22400\n",
      "Loss 0.00816582515835762, Accuracy 53.65625000000001%\n",
      "22400\n",
      "Loss 0.008271189406514168, Accuracy 52.861607142857146%\n",
      "22400\n",
      "Loss 0.008211266249418259, Accuracy 53.38392857142858%\n",
      "22400\n",
      "Loss 0.008150703273713589, Accuracy 53.40625%\n",
      "25600\n",
      "Loss 0.008178300224244595, Accuracy 53.63281250000001%\n",
      "25600\n",
      "Loss 0.008262649178504944, Accuracy 52.96875%\n",
      "25600\n",
      "Loss 0.008219754323363304, Accuracy 53.32812500000001%\n",
      "25600\n",
      "Loss 0.00813647173345089, Accuracy 53.515625%\n",
      "28800\n",
      "Loss 0.008169358596205711, Accuracy 53.72222222222223%\n",
      "28800\n",
      "Loss 0.008213836699724197, Accuracy 53.23611111111111%\n",
      "28800\n",
      "Loss 0.00821039266884327, Accuracy 53.267361111111114%\n",
      "28800\n",
      "Loss 0.008115671575069427, Accuracy 53.60069444444444%\n",
      "32000\n",
      "Loss 0.008171272464096546, Accuracy 53.5375%\n",
      "32000\n",
      "Loss 0.008226132020354271, Accuracy 53.131249999999994%\n",
      "32000\n",
      "Loss 0.008225283585488796, Accuracy 53.065625000000004%\n",
      "35200\n",
      "Loss 0.008226619102060795, Accuracy 53.19602272727273%\n",
      "35200\n",
      "Loss 0.008208400569856167, Accuracy 53.15625000000001%\n",
      "35200\n",
      "Loss 0.008177025243639946, Accuracy 53.46875%\n",
      "38400\n",
      "Loss 0.008163909427821636, Accuracy 53.643229166666664%\n",
      "38400\n",
      "Loss 0.008205391466617584, Accuracy 53.380208333333336%\n",
      "38400\n",
      "Loss 0.008195995353162289, Accuracy 53.24218750000001%\n",
      "41600\n",
      "Loss 0.008165199309587479, Accuracy 53.66586538461539%\n",
      "41600\n",
      "Loss 0.00820226315408945, Accuracy 53.40625%\n",
      "41600\n",
      "Loss 0.008196419104933739, Accuracy 53.28846153846154%\n",
      "44800\n",
      "Loss 0.008155656978487968, Accuracy 53.75%\n",
      "44800\n",
      "Loss 0.008174719288945198, Accuracy 53.56026785714286%\n",
      "44800\n",
      "Loss 0.008174591697752476, Accuracy 53.41294642857143%\n",
      "48000\n",
      "Loss 0.008146264590322971, Accuracy 53.75416666666667%\n",
      "48000\n",
      "Loss 0.008156274445354939, Accuracy 53.693749999999994%\n",
      "48000\n",
      "Loss 0.008168356493115425, Accuracy 53.44375%\n",
      "49500\n",
      "Loss 0.008144291117787361, Accuracy 53.7939393939394%\n",
      "Loss 0.008144291117787361, Accuracy 53.7939393939394%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.008155783638358116, Accuracy 53.73939393939394%\n",
      "Loss 0.008155783638358116, Accuracy 53.73939393939394%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.00815672893077135, Accuracy 53.59191919191919%\n",
      "Loss 0.00815672893077135, Accuracy 53.59191919191919%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 53%\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "3200\n",
      "Loss 0.008066440001130104, Accuracy 56.06250000000001%\n",
      "3200\n",
      "Loss 0.008147487416863441, Accuracy 51.71875%\n",
      "3200\n",
      "Loss 0.00804736278951168, Accuracy 54.09374999999999%\n",
      "6400\n",
      "Loss 0.008079416118562222, Accuracy 54.625%\n",
      "6400\n",
      "Loss 0.008109410293400288, Accuracy 53.78125%\n",
      "6400\n",
      "Loss 0.007958758622407913, Accuracy 54.65624999999999%\n",
      "9600\n",
      "Loss 0.008009552024304867, Accuracy 54.63541666666667%\n",
      "9600\n",
      "Loss 0.008030467666685581, Accuracy 54.322916666666664%\n",
      "9600\n",
      "Loss 0.007966033183038235, Accuracy 54.708333333333336%\n",
      "12800\n",
      "Loss 0.007993260398507118, Accuracy 54.8203125%\n",
      "12800\n",
      "Loss 0.008081842213869095, Accuracy 54.09374999999999%\n",
      "12800\n",
      "Loss 0.008002778515219688, Accuracy 54.48437499999999%\n",
      "16000\n",
      "Loss 0.008045651949942112, Accuracy 54.43125%\n",
      "16000\n",
      "Loss 0.007981720380485058, Accuracy 54.83749999999999%\n",
      "16000\n",
      "Loss 0.007931221276521683, Accuracy 55.037499999999994%\n",
      "19200\n",
      "Loss 0.007930183783173561, Accuracy 54.89062500000001%\n",
      "19200\n",
      "Loss 0.008034046739339828, Accuracy 54.557291666666664%\n",
      "19200\n",
      "Loss 0.007943903096020222, Accuracy 55.119791666666664%\n",
      "22400\n",
      "Loss 0.007903927937150002, Accuracy 54.986607142857146%\n",
      "22400\n",
      "Loss 0.008005544543266296, Accuracy 54.74553571428571%\n",
      "22400\n",
      "Loss 0.007950613275170326, Accuracy 55.044642857142854%\n",
      "25600\n",
      "Loss 0.007915628142654896, Accuracy 54.96484375%\n",
      "25600\n",
      "Loss 0.007994107902050018, Accuracy 54.8203125%\n",
      "25600\n",
      "Loss 0.007969307713210583, Accuracy 54.859375%\n",
      "28800\n",
      "Loss 0.007954776287078857, Accuracy 55.02430555555555%\n",
      "28800\n",
      "Loss 0.007965120486915112, Accuracy 54.86805555555555%\n",
      "28800\n",
      "Loss 0.007899245247244835, Accuracy 54.951388888888886%\n",
      "32000\n",
      "Loss 0.007896958850324154, Accuracy 54.900000000000006%\n",
      "32000\n",
      "Loss 0.00795750506222248, Accuracy 55.012499999999996%\n",
      "32000\n",
      "Loss 0.007987463846802711, Accuracy 54.625%\n",
      "35200\n",
      "Loss 0.007905236445367336, Accuracy 54.85227272727272%\n",
      "35200\n",
      "Loss 0.007951891049742699, Accuracy 55.10511363636363%\n",
      "35200\n",
      "Loss 0.007971671409904957, Accuracy 54.78125%\n",
      "38400\n",
      "Loss 0.007898803800344467, Accuracy 54.9453125%\n",
      "38400\n",
      "Loss 0.007927256636321545, Accuracy 55.27864583333333%\n",
      "38400\n",
      "Loss 0.007967936806380749, Accuracy 54.8359375%\n",
      "41600\n",
      "Loss 0.007897456176578999, Accuracy 54.99519230769231%\n",
      "41600\n",
      "Loss 0.007923373021185398, Accuracy 55.36538461538461%\n",
      "41600\n",
      "Loss 0.007976206950843334, Accuracy 54.77163461538461%\n",
      "44800\n",
      "Loss 0.00788880605250597, Accuracy 55.06473214285714%\n",
      "44800\n",
      "Loss 0.007894334383308887, Accuracy 55.484375%\n",
      "44800\n",
      "Loss 0.007957936264574528, Accuracy 54.877232142857146%\n",
      "48000\n",
      "Loss 0.007888003252446651, Accuracy 55.50416666666666%\n",
      "48000\n",
      "Loss 0.007948590442538261, Accuracy 54.90625%\n",
      "48000\n",
      "Loss 0.007881692610681057, Accuracy 55.06666666666666%\n",
      "49500\n",
      "Loss 0.00793699361383915, Accuracy 55.0020202020202%\n",
      "Loss 0.00793699361383915, Accuracy 55.0020202020202%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.007879448123276234, Accuracy 55.08888888888889%\n",
      "Loss 0.007879448123276234, Accuracy 55.08888888888889%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.007886531762778759, Accuracy 55.51313131313131%\n",
      "Loss 0.007886531762778759, Accuracy 55.51313131313131%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "3200\n",
      "Test set: running accuracy: 53%\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "9600\n",
      "Test set: running accuracy: 51%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "3200\n",
      "Loss 0.00783168338239193, Accuracy 56.03125%\n",
      "3200\n",
      "Loss 0.007884703576564789, Accuracy 54.78125%\n",
      "3200\n",
      "Loss 0.007811093702912331, Accuracy 56.6875%\n",
      "6400\n",
      "Loss 0.007842876948416233, Accuracy 56.09375%\n",
      "6400\n",
      "Loss 0.007829331792891026, Accuracy 55.984375%\n",
      "6400\n",
      "Loss 0.00769511004909873, Accuracy 56.99999999999999%\n",
      "9600\n",
      "Loss 0.007775451522320509, Accuracy 56.47916666666667%\n",
      "9600\n",
      "Loss 0.007734274957329035, Accuracy 56.770833333333336%\n",
      "9600\n",
      "Loss 0.00776183046400547, Accuracy 56.510416666666664%\n",
      "12800\n",
      "Loss 0.0077475011348724365, Accuracy 56.3984375%\n",
      "12800\n",
      "Loss 0.007817063480615616, Accuracy 56.09375%\n",
      "12800\n",
      "Loss 0.007733382750302553, Accuracy 56.625%\n",
      "16000\n",
      "Loss 0.0077826534397900105, Accuracy 56.33125%\n",
      "16000\n",
      "Loss 0.007742614019662142, Accuracy 56.675%\n",
      "16000\n",
      "Loss 0.0077103921212255955, Accuracy 56.61875%\n",
      "19200\n",
      "Loss 0.007781800348311663, Accuracy 56.28125000000001%\n",
      "19200\n",
      "Loss 0.007716147229075432, Accuracy 56.885416666666664%\n",
      "19200\n",
      "Loss 0.0077069830149412155, Accuracy 56.60937499999999%\n",
      "22400\n",
      "Loss 0.007770523428916931, Accuracy 56.43749999999999%\n",
      "22400\n",
      "Loss 0.007725147530436516, Accuracy 56.669642857142854%\n",
      "22400\n",
      "Loss 0.007684938609600067, Accuracy 56.825892857142854%\n",
      "25600\n",
      "Loss 0.007695404812693596, Accuracy 56.859375%\n",
      "25600\n",
      "Loss 0.007766055408865213, Accuracy 56.41406249999999%\n",
      "25600\n",
      "Loss 0.007745023351162672, Accuracy 56.5390625%\n",
      "28800\n",
      "Loss 0.00768215861171484, Accuracy 56.90277777777778%\n",
      "28800\n",
      "Loss 0.00772018963471055, Accuracy 56.64930555555555%\n",
      "28800\n",
      "Loss 0.007729103323072195, Accuracy 56.604166666666664%\n",
      "32000\n",
      "Loss 0.007679292466491461, Accuracy 56.825%\n",
      "32000\n",
      "Loss 0.0077224792912602425, Accuracy 56.553125%\n",
      "32000\n",
      "Loss 0.00774702662602067, Accuracy 56.46875%\n",
      "35200\n",
      "Loss 0.0076873283833265305, Accuracy 56.696022727272734%\n",
      "35200\n",
      "Loss 0.007720124442130327, Accuracy 56.57670454545455%\n",
      "35200\n",
      "Loss 0.007737763226032257, Accuracy 56.52556818181819%\n",
      "38400\n",
      "Loss 0.007727579213678837, Accuracy 56.49999999999999%\n",
      "38400\n",
      "Loss 0.007685408461838961, Accuracy 56.75781250000001%\n",
      "38400\n",
      "Loss 0.007694031577557325, Accuracy 56.794270833333336%\n",
      "41600\n",
      "Loss 0.007730472832918167, Accuracy 56.48076923076923%\n",
      "41600\n",
      "Loss 0.007684743031859398, Accuracy 56.76682692307692%\n",
      "41600\n",
      "Loss 0.007685465272516012, Accuracy 56.91826923076923%\n",
      "44800\n",
      "Loss 0.007660761009901762, Accuracy 57.004464285714285%\n",
      "44800\n",
      "Loss 0.0077041927725076675, Accuracy 56.611607142857146%\n",
      "44800\n",
      "Loss 0.007667131256312132, Accuracy 56.90848214285714%\n",
      "48000\n",
      "Loss 0.007698982022702694, Accuracy 56.58541666666667%\n",
      "48000\n",
      "Loss 0.007654940709471703, Accuracy 56.93541666666667%\n",
      "48000\n",
      "Loss 0.007641403004527092, Accuracy 57.18124999999999%\n",
      "49500\n",
      "Loss 0.007640516385436058, Accuracy 57.2060606060606%\n",
      "Loss 0.007640516385436058, Accuracy 57.2060606060606%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.007686109747737646, Accuracy 56.72121212121212%\n",
      "Loss 0.007686109747737646, Accuracy 56.72121212121212%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.007653886917978525, Accuracy 56.98181818181818%\n",
      "Loss 0.007653886917978525, Accuracy 56.98181818181818%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 53%\n",
      "3200\n",
      "Test set: running accuracy: 53%\n",
      "3200\n",
      "Test set: running accuracy: 51%\n",
      "6400\n",
      "Test set: running accuracy: 53%\n",
      "6400\n",
      "Test set: running accuracy: 53%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "9600\n",
      "Test set: running accuracy: 53%\n",
      "9600\n",
      "Test set: running accuracy: 53%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 53%\n",
      "12800\n",
      "Test set: running accuracy: 53%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 53%\n",
      "16000\n",
      "Test set: running accuracy: 53%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 53%\n",
      "19200\n",
      "Test set: running accuracy: 53%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 53%\n",
      "Test set: Accuracy: 53%\n",
      "22000\n",
      "Test set: running accuracy: 53%\n",
      "Test set: Accuracy: 53%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "3200\n",
      "Loss 0.007621030323207378, Accuracy 57.06250000000001%\n",
      "3200\n",
      "Loss 0.0074892775155603886, Accuracy 57.84375000000001%\n",
      "3200\n",
      "Loss 0.00784841738641262, Accuracy 55.375%\n",
      "6400\n",
      "Loss 0.007490269374102354, Accuracy 57.859375%\n",
      "6400\n",
      "Loss 0.007522785570472479, Accuracy 57.62500000000001%\n",
      "6400\n",
      "Loss 0.007750213146209717, Accuracy 56.65625%\n",
      "9600\n",
      "Loss 0.007496634963899851, Accuracy 57.739583333333336%\n",
      "9600\n",
      "Loss 0.007633989676833153, Accuracy 57.56250000000001%\n",
      "9600\n",
      "Loss 0.0075073265470564365, Accuracy 57.64583333333333%\n",
      "12800\n",
      "Loss 0.007655960973352194, Accuracy 57.1328125%\n",
      "12800\n",
      "Loss 0.007529984228312969, Accuracy 57.5234375%\n",
      "12800\n",
      "Loss 0.007503222674131393, Accuracy 57.921875%\n",
      "16000\n",
      "Loss 0.007524730637669563, Accuracy 57.96875%\n",
      "16000\n",
      "Loss 0.00745853828266263, Accuracy 58.44375000000001%\n",
      "16000\n",
      "Loss 0.0076246666721999645, Accuracy 57.199999999999996%\n",
      "19200\n",
      "Loss 0.007618455681949854, Accuracy 57.333333333333336%\n",
      "19200\n",
      "Loss 0.007498480379581451, Accuracy 58.15104166666667%\n",
      "19200\n",
      "Loss 0.007457210216671228, Accuracy 58.276041666666664%\n",
      "22400\n",
      "Loss 0.007601283024996519, Accuracy 57.46875%\n",
      "22400\n",
      "Loss 0.007502404041588306, Accuracy 58.03571428571429%\n",
      "22400\n",
      "Loss 0.0074446233920753, Accuracy 58.35267857142858%\n",
      "25600\n",
      "Loss 0.00759027898311615, Accuracy 57.51171874999999%\n",
      "25600\n",
      "Loss 0.007530239876359701, Accuracy 57.92578125%\n",
      "25600\n",
      "Loss 0.007467022631317377, Accuracy 58.2734375%\n",
      "28800\n",
      "Loss 0.007441310677677393, Accuracy 58.47569444444445%\n",
      "28800\n",
      "Loss 0.007540969178080559, Accuracy 57.8125%\n",
      "28800\n",
      "Loss 0.00751310121268034, Accuracy 57.920138888888886%\n",
      "32000\n",
      "Loss 0.0074434950947761536, Accuracy 58.275%\n",
      "32000\n",
      "Loss 0.00754653662443161, Accuracy 57.768750000000004%\n",
      "32000\n",
      "Loss 0.007527179084718227, Accuracy 57.75%\n",
      "35200\n",
      "Loss 0.007448325399309397, Accuracy 58.26136363636364%\n",
      "35200\n",
      "Loss 0.007538247387856245, Accuracy 57.86931818181819%\n",
      "35200\n",
      "Loss 0.00751036312431097, Accuracy 57.9375%\n",
      "38400\n",
      "Loss 0.007444337941706181, Accuracy 58.309895833333336%\n",
      "38400\n",
      "Loss 0.007512787822633982, Accuracy 57.984375%\n",
      "38400\n",
      "Loss 0.00750099727883935, Accuracy 58.01562500000001%\n",
      "41600\n",
      "Loss 0.007445527706295252, Accuracy 58.32932692307692%\n",
      "41600\n",
      "Loss 0.007506779860705137, Accuracy 58.03846153846154%\n",
      "41600\n",
      "Loss 0.00750481802970171, Accuracy 57.932692307692314%\n",
      "44800\n",
      "Loss 0.007430692203342915, Accuracy 58.439732142857146%\n",
      "44800\n",
      "Loss 0.007476109080016613, Accuracy 58.17857142857142%\n",
      "44800\n",
      "Loss 0.007482512388378382, Accuracy 58.04464285714286%\n",
      "48000\n",
      "Loss 0.0074578882195055485, Accuracy 58.331250000000004%\n",
      "48000\n",
      "Loss 0.007473404053598642, Accuracy 58.037499999999994%\n",
      "48000\n",
      "Loss 0.007416899316012859, Accuracy 58.53333333333334%\n",
      "49500\n",
      "Loss 0.007450544275343418, Accuracy 58.40808080808081%\n",
      "Loss 0.007450544275343418, Accuracy 58.40808080808081%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.0074623660184443, Accuracy 58.12525252525253%\n",
      "Loss 0.0074623660184443, Accuracy 58.12525252525253%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.007407285738736391, Accuracy 58.624242424242425%\n",
      "Loss 0.007407285738736391, Accuracy 58.624242424242425%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 53%\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "3200\n",
      "Test set: running accuracy: 53%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 53%\n",
      "6400\n",
      "Test set: running accuracy: 53%\n",
      "9600\n",
      "Test set: running accuracy: 53%\n",
      "9600\n",
      "Test set: running accuracy: 53%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 53%\n",
      "12800\n",
      "Test set: running accuracy: 53%\n",
      "16000\n",
      "Test set: running accuracy: 53%\n",
      "16000\n",
      "Test set: running accuracy: 53%\n",
      "16000\n",
      "Test set: running accuracy: 53%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 53%\n",
      "19200\n",
      "Test set: running accuracy: 53%\n",
      "22000\n",
      "Test set: running accuracy: 53%\n",
      "Test set: Accuracy: 53%\n",
      "22000\n",
      "Test set: running accuracy: 53%\n",
      "Test set: Accuracy: 53%\n",
      "22000\n",
      "Test set: running accuracy: 53%\n",
      "Test set: Accuracy: 53%\n",
      "3200\n",
      "Loss 0.0073689003475010395, Accuracy 59.8125%\n",
      "3200\n",
      "Loss 0.007390711922198534, Accuracy 59.06249999999999%\n",
      "3200\n",
      "Loss 0.00754137709736824, Accuracy 57.96875%\n",
      "6400\n",
      "Loss 0.007356258109211922, Accuracy 59.17187499999999%\n",
      "6400\n",
      "Loss 0.007480738218873739, Accuracy 58.609375%\n",
      "6400\n",
      "Loss 0.00726380106061697, Accuracy 59.9375%\n",
      "9600\n",
      "Loss 0.00729401595890522, Accuracy 59.48958333333333%\n",
      "9600\n",
      "Loss 0.007404455449432135, Accuracy 58.86458333333333%\n",
      "9600\n",
      "Loss 0.007327536586672068, Accuracy 59.59375%\n",
      "12800\n",
      "Loss 0.007327490020543337, Accuracy 59.49218750000001%\n",
      "12800\n",
      "Loss 0.007306728512048721, Accuracy 59.21875%\n",
      "12800\n",
      "Loss 0.0074104503728449345, Accuracy 58.75781249999999%\n",
      "16000\n",
      "Loss 0.007312169298529625, Accuracy 59.79375%\n",
      "16000\n",
      "Loss 0.007263049483299255, Accuracy 59.4375%\n",
      "16000\n",
      "Loss 0.007371916901320219, Accuracy 58.8625%\n",
      "19200\n",
      "Loss 0.007260169833898544, Accuracy 59.59895833333333%\n",
      "19200\n",
      "Loss 0.0073496089316904545, Accuracy 59.12500000000001%\n",
      "19200\n",
      "Loss 0.007273067720234394, Accuracy 59.921875%\n",
      "22400\n",
      "Loss 0.007233059965074062, Accuracy 59.86607142857143%\n",
      "22400\n",
      "Loss 0.0073299715295434, Accuracy 59.30803571428571%\n",
      "22400\n",
      "Loss 0.007271843031048775, Accuracy 59.875%\n",
      "25600\n",
      "Loss 0.007319569122046232, Accuracy 59.29296875%\n",
      "25600\n",
      "Loss 0.007289996836334467, Accuracy 59.640625%\n",
      "25600\n",
      "Loss 0.007237156853079796, Accuracy 59.83984375%\n",
      "28800\n",
      "Loss 0.0072160991840064526, Accuracy 59.92361111111111%\n",
      "28800\n",
      "Loss 0.007274038624018431, Accuracy 59.673611111111114%\n",
      "28800\n",
      "Loss 0.007277686148881912, Accuracy 59.72569444444444%\n",
      "32000\n",
      "Loss 0.007212805096060038, Accuracy 59.868750000000006%\n",
      "32000\n",
      "Loss 0.007281746249645948, Accuracy 59.550000000000004%\n",
      "32000\n",
      "Loss 0.007285807281732559, Accuracy 59.61562500000001%\n",
      "35200\n",
      "Loss 0.007275458890944719, Accuracy 59.690340909090914%\n",
      "35200\n",
      "Loss 0.007217395585030317, Accuracy 59.78693181818182%\n",
      "35200\n",
      "Loss 0.007271025329828262, Accuracy 59.66193181818183%\n",
      "38400\n",
      "Loss 0.007251928560435772, Accuracy 59.82291666666667%\n",
      "38400\n",
      "Loss 0.007266891188919544, Accuracy 59.68750000000001%\n",
      "38400\n",
      "Loss 0.007207302842289209, Accuracy 59.877604166666664%\n",
      "41600\n",
      "Loss 0.007209964096546173, Accuracy 59.88461538461538%\n",
      "41600\n",
      "Loss 0.0072478000074625015, Accuracy 59.77884615384615%\n",
      "44800\n",
      "Loss 0.007190163247287273, Accuracy 60.011160714285715%\n",
      "44800\n",
      "Loss 0.0072151068598032, Accuracy 59.973214285714285%\n",
      "48000\n",
      "Loss 0.007205040659755468, Accuracy 60.05625%\n",
      "48000\n",
      "Loss 0.0071855164133012295, Accuracy 59.97291666666666%\n",
      "49500\n",
      "Loss 0.007178080268204212, Accuracy 60.02424242424242%\n",
      "Loss 0.007178080268204212, Accuracy 60.02424242424242%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.0072019752115011215, Accuracy 60.09090909090909%\n",
      "Loss 0.0072019752115011215, Accuracy 60.09090909090909%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 54%\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 53%\n",
      "6400\n",
      "Test set: running accuracy: 53%\n",
      "9600\n",
      "Test set: running accuracy: 53%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 53%\n",
      "16000\n",
      "Test set: running accuracy: 53%\n",
      "16000\n",
      "Test set: running accuracy: 53%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "3200\n",
      "Loss 0.007154319901019335, Accuracy 60.68750000000001%\n",
      "3200\n",
      "Loss 0.007253160700201988, Accuracy 60.0625%\n",
      "6400\n",
      "Loss 0.007073297630995512, Accuracy 60.953125%\n",
      "6400\n",
      "Loss 0.0072196898981928825, Accuracy 60.390625%\n",
      "9600\n",
      "Loss 0.007048286031931639, Accuracy 61.083333333333336%\n",
      "9600\n",
      "Loss 0.007145753595978022, Accuracy 60.979166666666664%\n",
      "12800\n",
      "Loss 0.007031779270619154, Accuracy 60.92968749999999%\n",
      "12800\n",
      "Loss 0.007147443480789661, Accuracy 60.984375%\n",
      "16000\n",
      "Loss 0.006982958875596523, Accuracy 61.368750000000006%\n",
      "16000\n",
      "Loss 0.007092106621712446, Accuracy 61.11875%\n",
      "19200\n",
      "Loss 0.006999916397035122, Accuracy 61.083333333333336%\n",
      "19200\n",
      "Loss 0.007097018416970968, Accuracy 61.119791666666664%\n",
      "22400\n",
      "Loss 0.0069772591814398766, Accuracy 61.24107142857142%\n",
      "22400\n",
      "Loss 0.0070798443630337715, Accuracy 61.294642857142854%\n",
      "25600\n",
      "Loss 0.006971387192606926, Accuracy 61.27343750000001%\n",
      "25600\n",
      "Loss 0.007063437253236771, Accuracy 61.37890625%\n",
      "28800\n",
      "Loss 0.007027570623904467, Accuracy 61.53125000000001%\n",
      "28800\n",
      "Loss 0.006956269033253193, Accuracy 61.295138888888886%\n",
      "32000\n",
      "Loss 0.006956653203815222, Accuracy 61.184375%\n",
      "32000\n",
      "Loss 0.007018844597041607, Accuracy 61.493750000000006%\n",
      "35200\n",
      "Loss 0.006957766134291887, Accuracy 61.16193181818181%\n",
      "35200\n",
      "Loss 0.007008139044046402, Accuracy 61.517045454545446%\n",
      "38400\n",
      "Loss 0.006959087681025267, Accuracy 61.21875%\n",
      "38400\n",
      "Loss 0.006993950344622135, Accuracy 61.5859375%\n",
      "41600\n",
      "Loss 0.006965250708162785, Accuracy 61.16105769230769%\n",
      "41600\n",
      "Loss 0.006981431506574154, Accuracy 61.68749999999999%\n",
      "44800\n",
      "Loss 0.006948518101125956, Accuracy 61.316964285714285%\n",
      "44800\n",
      "Loss 0.006956866011023521, Accuracy 61.83482142857143%\n",
      "48000\n",
      "Loss 0.006942796055227518, Accuracy 61.35625%\n",
      "48000\n",
      "Loss 0.006941459607332945, Accuracy 61.975%\n",
      "49500\n",
      "Loss 0.00693562813103199, Accuracy 61.438383838383835%\n",
      "Loss 0.00693562813103199, Accuracy 61.438383838383835%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.006932862102985382, Accuracy 62.090909090909086%\n",
      "Loss 0.006932862102985382, Accuracy 62.090909090909086%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "9600\n",
      "Test set: running accuracy: 53%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "3200\n",
      "Loss 0.006943957880139351, Accuracy 61.625%\n",
      "3200\n",
      "Loss 0.006899699103087187, Accuracy 62.9375%\n",
      "6400\n",
      "Loss 0.006851719692349434, Accuracy 62.546875%\n",
      "6400\n",
      "Loss 0.006863778457045555, Accuracy 62.125%\n",
      "9600\n",
      "Loss 0.00679027708247304, Accuracy 62.84375%\n",
      "9600\n",
      "Loss 0.006849010940641165, Accuracy 62.27083333333333%\n",
      "12800\n",
      "Loss 0.006780467461794615, Accuracy 62.953125%\n",
      "12800\n",
      "Loss 0.0068923067301511765, Accuracy 62.0625%\n",
      "16000\n",
      "Loss 0.0067413668148219585, Accuracy 63.28125%\n",
      "16000\n",
      "Loss 0.006852205377072096, Accuracy 62.224999999999994%\n",
      "19200\n",
      "Loss 0.006737896706908941, Accuracy 63.22916666666667%\n",
      "19200\n",
      "Loss 0.006866965442895889, Accuracy 62.286458333333336%\n",
      "22400\n",
      "Loss 0.006860662717372179, Accuracy 62.39732142857143%\n",
      "22400\n",
      "Loss 0.006722963880747557, Accuracy 63.25892857142858%\n",
      "25600\n",
      "Loss 0.006731834262609482, Accuracy 63.2578125%\n",
      "25600\n",
      "Loss 0.0068401456810534, Accuracy 62.44140625%\n",
      "28800\n",
      "Loss 0.006697927601635456, Accuracy 63.458333333333336%\n",
      "28800\n",
      "Loss 0.006792626343667507, Accuracy 62.746527777777786%\n",
      "32000\n",
      "Loss 0.006704961881041527, Accuracy 63.290625%\n",
      "32000\n",
      "Loss 0.006792226806282997, Accuracy 62.721875000000004%\n",
      "35200\n",
      "Loss 0.006712975446134806, Accuracy 63.19602272727273%\n",
      "35200\n",
      "Loss 0.006789390463382006, Accuracy 62.80681818181818%\n",
      "38400\n",
      "Loss 0.006699947640299797, Accuracy 63.3046875%\n",
      "38400\n",
      "Loss 0.006767547223716974, Accuracy 62.90625%\n",
      "41600\n",
      "Loss 0.00670006824657321, Accuracy 63.21153846153847%\n",
      "41600\n",
      "Loss 0.0067533147521317005, Accuracy 63.04807692307692%\n",
      "44800\n",
      "Loss 0.006688796915113926, Accuracy 63.263392857142854%\n",
      "44800\n",
      "Loss 0.00671781599521637, Accuracy 63.234375%\n",
      "48000\n",
      "Loss 0.006680628284811974, Accuracy 63.31666666666666%\n",
      "48000\n",
      "Loss 0.006703999824821949, Accuracy 63.35833333333334%\n",
      "49500\n",
      "Loss 0.006674501579254866, Accuracy 63.41616161616162%\n",
      "Loss 0.006674501579254866, Accuracy 63.41616161616162%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.006695523392409086, Accuracy 63.40606060606061%\n",
      "Loss 0.006695523392409086, Accuracy 63.40606060606061%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 51%\n",
      "3200\n",
      "Test set: running accuracy: 51%\n",
      "6400\n",
      "Test set: running accuracy: 51%\n",
      "6400\n",
      "Test set: running accuracy: 51%\n",
      "9600\n",
      "Test set: running accuracy: 51%\n",
      "9600\n",
      "Test set: running accuracy: 51%\n",
      "12800\n",
      "Test set: running accuracy: 51%\n",
      "12800\n",
      "Test set: running accuracy: 51%\n",
      "16000\n",
      "Test set: running accuracy: 51%\n",
      "16000\n",
      "Test set: running accuracy: 51%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "2022-12-04 16:45:06,868 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2022-12-04 16:45:06,868 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2022-12-04 16:45:06,868 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "2022-12-04 16:45:44,155 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2022-12-04 16:45:44,155 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2022-12-04 16:45:44,155 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2022-12-04 16:47:08 Uploading - Uploading generated training model\n",
      "2022-12-04 16:47:08 Completed - Training job completed\n",
      "ProfilerReport-1670133811: NoIssuesFound\n",
      "32000\n",
      "Loss 0.008136316202580929, Accuracy 53.525%\n",
      "35200\n",
      "Loss 0.008146311156451702, Accuracy 53.55113636363637%\n",
      "38400\n",
      "Loss 0.00814879685640335, Accuracy 53.5390625%\n",
      "41600\n",
      "Loss 0.008143240585923195, Accuracy 53.526442307692314%\n",
      "44800\n",
      "Loss 0.008127762004733086, Accuracy 53.64955357142858%\n",
      "48000\n",
      "Loss 0.008132428862154484, Accuracy 53.65416666666667%\n",
      "49500\n",
      "Loss 0.008141308091580868, Accuracy 53.71919191919192%\n",
      "Loss 0.008141308091580868, Accuracy 53.71919191919192%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "3200\n",
      "Loss 0.0079996632412076, Accuracy 54.46875%\n",
      "6400\n",
      "Loss 0.00803566724061966, Accuracy 54.37499999999999%\n",
      "9600\n",
      "Loss 0.007996589876711369, Accuracy 54.58333333333333%\n",
      "12800\n",
      "Loss 0.008004552684724331, Accuracy 54.5390625%\n",
      "16000\n",
      "Loss 0.0079673882573843, Accuracy 54.731249999999996%\n",
      "19200\n",
      "Loss 0.007934394292533398, Accuracy 54.91145833333333%\n",
      "22400\n",
      "Loss 0.007896466180682182, Accuracy 55.049107142857146%\n",
      "25600\n",
      "Loss 0.007883933372795582, Accuracy 55.20703125000001%\n",
      "28800\n",
      "Loss 0.007871067151427269, Accuracy 55.20138888888889%\n",
      "32000\n",
      "Loss 0.007891302928328514, Accuracy 55.074999999999996%\n",
      "35200\n",
      "Loss 0.007894798181951046, Accuracy 55.04829545454546%\n",
      "38400\n",
      "Loss 0.007888427935540676, Accuracy 55.098958333333336%\n",
      "41600\n",
      "Loss 0.00789323914796114, Accuracy 55.11538461538461%\n",
      "44800\n",
      "Loss 0.007880176417529583, Accuracy 55.22767857142858%\n",
      "48000\n",
      "Loss 0.007875030860304832, Accuracy 55.21458333333334%\n",
      "49500\n",
      "Loss 0.007882502861320972, Accuracy 55.16969696969697%\n",
      "Loss 0.007882502861320972, Accuracy 55.16969696969697%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 51%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 53%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "3200\n",
      "Loss 0.007729098666459322, Accuracy 57.15625%\n",
      "6400\n",
      "Loss 0.007757094688713551, Accuracy 56.28125000000001%\n",
      "9600\n",
      "Loss 0.0076958006247878075, Accuracy 56.92708333333333%\n",
      "12800\n",
      "Loss 0.007725234609097242, Accuracy 56.625%\n",
      "16000\n",
      "Loss 0.007717975415289402, Accuracy 56.675%\n",
      "19200\n",
      "Loss 0.007708817254751921, Accuracy 56.604166666666664%\n",
      "22400\n",
      "Loss 0.007677820976823568, Accuracy 56.75446428571429%\n",
      "25600\n",
      "Loss 0.007663664873689413, Accuracy 56.79296874999999%\n",
      "28800\n",
      "Loss 0.007655343506485224, Accuracy 56.767361111111114%\n",
      "32000\n",
      "Loss 0.007670442573726177, Accuracy 56.746874999999996%\n",
      "35200\n",
      "Loss 0.007683569099754095, Accuracy 56.69034090909091%\n",
      "38400\n",
      "Loss 0.007677882444113493, Accuracy 56.677083333333336%\n",
      "41600\n",
      "Loss 0.007673355750739574, Accuracy 56.6923076923077%\n",
      "44800\n",
      "Loss 0.007663873955607414, Accuracy 56.783482142857146%\n",
      "48000\n",
      "Loss 0.007653689477592707, Accuracy 56.81458333333333%\n",
      "49500\n",
      "Loss 0.007656743284314871, Accuracy 56.87878787878788%\n",
      "Loss 0.007656743284314871, Accuracy 56.87878787878788%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 53%\n",
      "16000\n",
      "Test set: running accuracy: 53%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "3200\n",
      "Loss 0.007585613057017326, Accuracy 58.12500000000001%\n",
      "6400\n",
      "Loss 0.007505821064114571, Accuracy 58.65625%\n",
      "9600\n",
      "Loss 0.007488855626434088, Accuracy 58.9375%\n",
      "12800\n",
      "Loss 0.007506787311285734, Accuracy 58.2265625%\n",
      "16000\n",
      "Loss 0.007492356933653355, Accuracy 58.12500000000001%\n",
      "19200\n",
      "Loss 0.007462173234671354, Accuracy 58.21875%\n",
      "22400\n",
      "Loss 0.007424366660416126, Accuracy 58.37946428571429%\n",
      "25600\n",
      "Loss 0.007410834543406963, Accuracy 58.375%\n",
      "28800\n",
      "Loss 0.007390928920358419, Accuracy 58.4375%\n",
      "32000\n",
      "Loss 0.007399294059723616, Accuracy 58.5%\n",
      "35200\n",
      "Loss 0.007405400741845369, Accuracy 58.46306818181818%\n",
      "38400\n",
      "Loss 0.007402997929602861, Accuracy 58.510416666666664%\n",
      "41600\n",
      "Loss 0.007406916469335556, Accuracy 58.40625000000001%\n",
      "44800\n",
      "Loss 0.007397410459816456, Accuracy 58.466517857142854%\n",
      "48000\n",
      "Loss 0.0073883794248104095, Accuracy 58.575%\n",
      "49500\n",
      "Loss 0.007392283994704485, Accuracy 58.57373737373738%\n",
      "Loss 0.007392283994704485, Accuracy 58.57373737373738%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 53%\n",
      "6400\n",
      "Test set: running accuracy: 53%\n",
      "9600\n",
      "Test set: running accuracy: 53%\n",
      "12800\n",
      "Test set: running accuracy: 53%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 53%\n",
      "22000\n",
      "Test set: running accuracy: 53%\n",
      "Test set: Accuracy: 53%\n",
      "3200\n",
      "Loss 0.007408836390823126, Accuracy 57.56250000000001%\n",
      "6400\n",
      "Loss 0.007305781356990337, Accuracy 58.39062499999999%\n",
      "9600\n",
      "Loss 0.00724634388461709, Accuracy 59.197916666666664%\n",
      "12800\n",
      "Loss 0.007277464959770441, Accuracy 58.95312499999999%\n",
      "16000\n",
      "Loss 0.007249794434756041, Accuracy 59.112500000000004%\n",
      "19200\n",
      "Loss 0.007237826939672232, Accuracy 59.08333333333333%\n",
      "22400\n",
      "Loss 0.00720843905583024, Accuracy 59.29017857142858%\n",
      "25600\n",
      "Loss 0.007198850624263287, Accuracy 59.3359375%\n",
      "28800\n",
      "Loss 0.007172322832047939, Accuracy 59.513888888888886%\n",
      "32000\n",
      "Loss 0.007190595846623182, Accuracy 59.521875%\n",
      "35200\n",
      "Loss 0.007196789141744375, Accuracy 59.51136363636363%\n",
      "38400\n",
      "Loss 0.007192430552095175, Accuracy 59.510416666666664%\n",
      "41600\n",
      "Loss 0.007265476044267416, Accuracy 59.66826923076923%\n",
      "41600\n",
      "Loss 0.0071959830820560455, Accuracy 59.473557692307686%\n",
      "44800\n",
      "Loss 0.007234068121761084, Accuracy 59.81696428571428%\n",
      "44800\n",
      "Loss 0.007185155991464853, Accuracy 59.59821428571429%\n",
      "48000\n",
      "Loss 0.007229304406791925, Accuracy 59.704166666666666%\n",
      "48000\n",
      "Loss 0.007184275891631842, Accuracy 59.64791666666667%\n",
      "49500\n",
      "Loss 0.007183464244008064, Accuracy 59.753535353535355%\n",
      "Loss 0.007183464244008064, Accuracy 59.753535353535355%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.0072133406065404415, Accuracy 59.830303030303035%\n",
      "Loss 0.0072133406065404415, Accuracy 59.830303030303035%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "9600\n",
      "Test set: running accuracy: 53%\n",
      "9600\n",
      "Test set: running accuracy: 53%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 53%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 53%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 53%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 53%\n",
      "Test set: Accuracy: 53%\n",
      "3200\n",
      "Loss 0.007126239128410816, Accuracy 59.9375%\n",
      "3200\n",
      "Loss 0.007011814042925835, Accuracy 60.5%\n",
      "6400\n",
      "Loss 0.0070130894891917706, Accuracy 60.4375%\n",
      "6400\n",
      "Loss 0.007062343880534172, Accuracy 60.23437499999999%\n",
      "9600\n",
      "Loss 0.007035400252789259, Accuracy 60.34374999999999%\n",
      "9600\n",
      "Loss 0.0070220851339399815, Accuracy 60.66666666666667%\n",
      "12800\n",
      "Loss 0.007038688752800226, Accuracy 60.4609375%\n",
      "12800\n",
      "Loss 0.0070591215044260025, Accuracy 60.3984375%\n",
      "16000\n",
      "Loss 0.007015045266598463, Accuracy 60.73125%\n",
      "16000\n",
      "Loss 0.007062702905386686, Accuracy 60.712500000000006%\n",
      "19200\n",
      "Loss 0.007045668549835682, Accuracy 61.010416666666664%\n",
      "19200\n",
      "Loss 0.007022805977612734, Accuracy 60.807291666666664%\n",
      "22400\n",
      "Loss 0.007050216663628817, Accuracy 60.964285714285715%\n",
      "22400\n",
      "Loss 0.006979658268392086, Accuracy 61.017857142857146%\n",
      "25600\n",
      "Loss 0.007069117855280638, Accuracy 60.890625%\n",
      "25600\n",
      "Loss 0.00697344308719039, Accuracy 61.18359375%\n",
      "28800\n",
      "Loss 0.007048687431961298, Accuracy 61.0%\n",
      "28800\n",
      "Loss 0.0069491504691541195, Accuracy 61.37152777777778%\n",
      "32000\n",
      "Loss 0.006952215917408466, Accuracy 61.34375%\n",
      "32000\n",
      "Loss 0.007066886406391859, Accuracy 60.871874999999996%\n",
      "35200\n",
      "Loss 0.007055007386952639, Accuracy 60.91193181818182%\n",
      "35200\n",
      "Loss 0.006950769107788801, Accuracy 61.39204545454545%\n",
      "38400\n",
      "Loss 0.006949658505618572, Accuracy 61.3671875%\n",
      "38400\n",
      "Loss 0.007051070686429739, Accuracy 60.890625%\n",
      "41600\n",
      "Loss 0.00704957963898778, Accuracy 60.894230769230774%\n",
      "41600\n",
      "Loss 0.006941874511539936, Accuracy 61.37019230769231%\n",
      "44800\n",
      "Loss 0.007020826451480389, Accuracy 61.046875%\n",
      "44800\n",
      "Loss 0.006929109338670969, Accuracy 61.49553571428571%\n",
      "48000\n",
      "Loss 0.007013043854385614, Accuracy 61.03541666666666%\n",
      "48000\n",
      "Loss 0.006923604290932417, Accuracy 61.545833333333334%\n",
      "49500\n",
      "Loss 0.00691972766071558, Accuracy 61.60606060606061%\n",
      "Loss 0.00691972766071558, Accuracy 61.60606060606061%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.006993141025304794, Accuracy 61.14747474747475%\n",
      "Loss 0.006993141025304794, Accuracy 61.14747474747475%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 51%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "9600\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "3200\n",
      "Loss 0.0068360548466444016, Accuracy 62.03125000000001%\n",
      "3200\n",
      "Loss 0.006842029746621847, Accuracy 61.8125%\n",
      "6400\n",
      "Loss 0.006755166687071323, Accuracy 62.484375%\n",
      "6400\n",
      "Loss 0.0068536484614014626, Accuracy 62.0%\n",
      "9600\n",
      "Loss 0.0067510479129850864, Accuracy 62.583333333333336%\n",
      "9600\n",
      "Loss 0.00680461386218667, Accuracy 62.427083333333336%\n",
      "12800\n",
      "Loss 0.0067932321690022945, Accuracy 62.4375%\n",
      "12800\n",
      "Loss 0.006804664619266987, Accuracy 62.2421875%\n",
      "16000\n",
      "Loss 0.006781830918043852, Accuracy 62.35000000000001%\n",
      "16000\n",
      "Loss 0.006780160125344992, Accuracy 62.5625%\n",
      "19200\n",
      "Loss 0.006757370661944151, Accuracy 62.677083333333336%\n",
      "19200\n",
      "Loss 0.006769014056771994, Accuracy 62.4375%\n",
      "22400\n",
      "Loss 0.006789347622543573, Accuracy 62.236607142857146%\n",
      "22400\n",
      "Loss 0.0067468807101249695, Accuracy 62.83928571428572%\n",
      "25600\n",
      "Loss 0.00679039815440774, Accuracy 62.21484375000001%\n",
      "25600\n",
      "Loss 0.006737242452800274, Accuracy 62.86328125%\n",
      "28800\n",
      "Loss 0.006768227554857731, Accuracy 62.34027777777777%\n",
      "28800\n",
      "Loss 0.006723781116306782, Accuracy 62.88888888888889%\n",
      "32000\n",
      "Loss 0.006736744195222855, Accuracy 62.956250000000004%\n",
      "32000\n",
      "Loss 0.0067895581014454365, Accuracy 62.221875000000004%\n",
      "35200\n",
      "Loss 0.006736408919095993, Accuracy 62.92329545454546%\n",
      "35200\n",
      "Loss 0.0067884367890655994, Accuracy 62.298295454545446%\n",
      "38400\n",
      "Loss 0.006785375066101551, Accuracy 62.29687499999999%\n",
      "38400\n",
      "Loss 0.006726286374032497, Accuracy 62.9609375%\n",
      "41600\n",
      "Loss 0.006784777157008648, Accuracy 62.31971153846154%\n",
      "41600\n",
      "Loss 0.006717049516737461, Accuracy 62.87740384615385%\n",
      "44800\n",
      "Loss 0.006747853942215443, Accuracy 62.582589285714285%\n",
      "44800\n",
      "Loss 0.006703637074679136, Accuracy 63.02455357142858%\n",
      "48000\n",
      "Loss 0.006697674281895161, Accuracy 62.958333333333336%\n",
      "48000\n",
      "Loss 0.006731694098562002, Accuracy 62.6375%\n",
      "49500\n",
      "Loss 0.006694061681628227, Accuracy 62.997979797979795%\n",
      "Loss 0.006694061681628227, Accuracy 62.997979797979795%\n",
      "Test size: 172\n",
      "49500\n",
      "Loss 0.006716927979141474, Accuracy 62.763636363636365%\n",
      "Loss 0.006716927979141474, Accuracy 62.763636363636365%\n",
      "Test size: 172\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "3200\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 52%\n",
      "6400\n",
      "Test set: running accuracy: 51%\n",
      "9600\n",
      "Test set: running accuracy: 53%\n",
      "9600\n",
      "Test set: running accuracy: 51%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "12800\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "16000\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "19200\n",
      "Test set: running accuracy: 52%\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "2022-12-04 16:45:44,745 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2022-12-04 16:45:44,745 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2022-12-04 16:45:44,746 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "22000\n",
      "Test set: running accuracy: 52%\n",
      "Test set: Accuracy: 52%\n",
      "2022-12-04 16:46:10,052 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2022-12-04 16:46:10,052 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2022-12-04 16:46:10,052 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "Training seconds: 154096\n",
      "Billable seconds: 74024\n",
      "Managed Spot Training savings: 52.0%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fit your estimator\n",
    "os.environ['SM_CHANNEL_TRAIN']='s3://awscapstone/train_data/'\n",
    "os.environ['SM_CHANNEL_TEST']='s3://awscapstone/test_data/'\n",
    "os.environ['SM_MODEL_DIR']='s3://awscapstone/'\n",
    "estimator.fit({\"train\": os.environ['SM_CHANNEL_TRAIN'], \"test\": os.environ['SM_CHANNEL_TEST'] }, wait=True)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Sep 28 2021, 16:10:42) \n[GCC 9.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b9a16027b1face11683377a0f72853ed9096586e91733d0ba9340678d80f683"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
